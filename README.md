# Proyecto RAG â€“ ANStein ğŸš€

Este proyecto es una implementaciÃ³n de un sistema **Retrieval-Augmented Generation (RAG)** enfocado en el Ã¡mbito de la docencia en fÃ­sica. Utiliza tÃ©cnicas de recuperaciÃ³n y generaciÃ³n de respuestas para ayudar a resolver dudas o explicar conceptos en Ã¡reas especÃ­ficas de la fÃ­sica, tales como **MecÃ¡nica**, **Electromagnetismo**, **TermodinÃ¡mica**, **FÃ­sica CuÃ¡ntica** y **FÃ­sica General**. ğŸ¤“

El sistema combina la descarga y el preprocesamiento de documentos (PDFs) con la generaciÃ³n de respuestas usando modelos de lenguaje (utilizando *langchain*, *ChatOpenAI* y *chainlit*), junto con el almacenamiento y consulta de embeddings en una base de datos vectorial (*ChromaDB*).

---

## CaracterÃ­sticas âœ¨

- **Descarga y Preprocesamiento de Documentos:**  
  Descarga automÃ¡ticamente PDFs listados en `urls.txt`, los preprocesa y los fragmenta en secciones Ãºtiles para la bÃºsqueda y recuperaciÃ³n de informaciÃ³n. ğŸ“„â¡ï¸ğŸ“š

- **Consulta y Respuesta DinÃ¡mica:**  
  Al iniciar la aplicaciÃ³n, se invita al usuario a seleccionar un mÃ³dulo (por ejemplo, *MecÃ¡nica*, *Electromagnetismo*, etc.) y posteriormente se responde a las preguntas en el contexto del Ã¡rea seleccionada. ğŸ’¬âœ…

- **Historial de Conversaciones:**  
  Se mantiene un historial en memoria para mejorar la interacciÃ³n y el contexto en conversaciones posteriores. ğŸ—‚ï¸

- **IntegraciÃ³n con Chainlit:**  
  La interfaz de usuario se basa en Chainlit, que permite una interacciÃ³n sencilla y visual con la aplicaciÃ³n. ğŸ¨

- **Requiere Clave de OPENAI:**  
  Es **necesario** disponer de una clave de OPENAI para el correcto funcionamiento del modelo de lenguaje. Esta clave debe ser alojada en un archivo `.env` al crear el proyecto. ğŸ”‘

---

## Estructura del Proyecto ğŸ“
```
â””â”€â”€ yanruwu-rag/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ chainlit.md          # GuÃ­a de usuario para la interfaz Chainlit.
    â”œâ”€â”€ main.py              # Script principal: descarga, preprocesamiento y chat.
    â”œâ”€â”€ requirements.yml     # Lista de dependencias.
    â”œâ”€â”€ urls.txt             # URLs de los PDFs a descargar.
    â”œâ”€â”€ chroma_db/          # Base de datos vectorial (ChromaDB).
    â”œâ”€â”€ public/             # Recursos pÃºblicos.
    â”œâ”€â”€ src/                # CÃ³digo fuente del proyecto.
    â”‚   â”œâ”€â”€ doc_load.py      # Descarga de PDFs.
    â”‚   â”œâ”€â”€ memory_chat.py   # ConfiguraciÃ³n del chat y manejo del historial.
    â”‚   â””â”€â”€ preprocessing.py # Preprocesamiento: fragmentaciÃ³n, limpieza y generaciÃ³n de embeddings.
    â””â”€â”€ .chainlit/          # ConfiguraciÃ³n de Chainlit.
        â”œâ”€â”€ config.toml      # Ajustes de la interfaz.
        â””â”€â”€ translations/    # Archivos de traducciÃ³n de chainlit.
```

---

## InstalaciÃ³n ğŸ’»

1. **Clonar el repositorio:**

```bash
git clone https://github.com/yanruwu/RAG.git
cd RAG
```
2. **Crear el entorno de Conda y activar:**
```bash
conda env create -f requirements.yml
conda activate anstein-rag
```
3. **Instalar las dependencias de pip:**

Las dependencias listadas en requirements.yml se instalarÃ¡n automÃ¡ticamente al crear el entorno. Si usas otro gestor, asegÃºrate de instalar:
- pypdf
- chainlit
- langchain
- deep_translator
- langdetect
- sentence-transformers
- chromadb
- langchain_openai
- langchain_community
4. **Configurar la clave de OPENAI:**
Crea un archivo .env en la raÃ­z del proyecto y aÃ±ade tu clave de OPENAI:
```env
OPENAI_API_KEY=tu_clave_de_openai_aqui
```
---
## Uso ğŸ”§

1. **Descarga y Preprocesamiento:**

Al ejecutar main.py, se realizarÃ¡ lo siguiente:

- Se leen las URLs de urls.txt y se descargan los documentos PDF (almacenados en el directorio docs).
- Se preprocesan los PDFs: se dividen en fragmentos basados en oraciones usando SpaCy, se generan embeddings con SentenceTransformer y se almacenan en ChromaDB.

2. **Inicio del Chat:**

Al iniciar la aplicaciÃ³n, Chainlit mostrarÃ¡ un mensaje de bienvenida con botones para seleccionar un mÃ³dulo (por ejemplo, MecÃ¡nica, Electromagnetismo, etc.). Una vez seleccionado, el usuario podrÃ¡:

- Enviar preguntas relacionadas con el Ã¡rea de fÃ­sica seleccionada.
- El sistema traducirÃ¡ (si es necesario), recuperarÃ¡ el contexto relevante y generarÃ¡ una respuesta utilizando el modelo configurado. ğŸ¤–
---
## ConfiguraciÃ³n âš™ï¸
- **Chainlit:**
El archivo .chainlit/config.toml contiene la configuraciÃ³n de la interfaz.

- **Embeddings y Base de Datos Vectorial:**
La configuraciÃ³n de preprocesamiento y consulta se define en ``src/preprocessing.py``, donde se especifica el directorio de persistencia para ChromaDB y el modelo de embeddings a utilizar.

- **Modelos y API:**
En ``src/memory_chat.py`` se configura el modelo de lenguaje (por ejemplo, ChatOpenAI con modelo ``gpt-4o-mini-2024-07-18``).
---

## Ejemplo
El inicio de chat da la opciÃ³n de elegir el Ã¡rea concreta para basar la respuesta.

![Inicio de chat](/public/imgs/test1.png)

Podemos seguir conversando con el chatbot, el cual mantiene la memoria de la conversaciÃ³n:

![DemostraciÃ³n de memoria](/public/imgs/test2.png)

AdemÃ¡s, las expresiones matemÃ¡ticas se formatean con LaTeX, lo que permite una muestra clara y entendible. El modelo tambiÃ©n provee las fuentes de donde saca la informaciÃ³n para permitir al usuario consultarlas por sÃ­ mismo.

---

## Contribuciones ğŸ¤
Si deseas contribuir al proyecto, siÃ©ntete libre de abrir issues o pull requests. Las contribuciones para mejorar la funcionalidad, la documentaciÃ³n o la traducciÃ³n a otros idiomas serÃ¡n muy bien recibidas.



